{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Specify the path to your ZIP file\n",
        "zip_file_path = '/content/archive.zip'  # Change this to the path of your ZIP file\n",
        "\n",
        "# Specify the directory where you want to extract the contents\n",
        "extracted_dir_path = '/content/Imagedataset'  # Change this to your desired extraction directory\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "import os\n",
        "os.makedirs(extracted_dir_path, exist_ok=True)\n",
        "\n",
        "# Open the ZIP file and extract its contents\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_dir_path)\n",
        "\n",
        "# List the extracted files and directories\n",
        "extracted_files = os.listdir(extracted_dir_path)\n",
        "print(\"Extracted files and directories:\")\n",
        "for item in extracted_files:\n",
        "    print(item)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRkI3MX5ShLf",
        "outputId": "f0d12fc6-5193-410a-eba3-dd64014a6d5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted files and directories:\n",
            "cropped_images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJHZwbP5Q4Th",
        "outputId": "c49fb766-71d4-4b5b-b778-0051089dac1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo56.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo7.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo20.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo43.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo22.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo38.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo3.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo28.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo62.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo36.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo16.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo2.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo4.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo59.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo48.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo6.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo33.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo61.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo65.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo57.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo9.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo18.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo10.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo34.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo13.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo1.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo15.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo21.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo47.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo5.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo66.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo8.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo53.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo63.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo52.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo30.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo24.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo42.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo39.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo46.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo31.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo35.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo45.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo60.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo55.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo27.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo19.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo11.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo23.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo58.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo44.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo50.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo25.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo17.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo41.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo37.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo51.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo64.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo12.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo40.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo32.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo54.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo26.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo14.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo29.png\n",
            "/content/Imagedataset/cropped_images/mark_ruffalo/mark_ruffalo49.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson39.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson44.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson30.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson54.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson10.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson43.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson15.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson35.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson45.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson18.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson8.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson28.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson9.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson32.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson29.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson38.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson19.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson21.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson25.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson46.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson51.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson3.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson6.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson20.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson37.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson2.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson12.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson41.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson27.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson26.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson40.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson48.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson36.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson42.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson52.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson23.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson34.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson24.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson50.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson33.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson4.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson5.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson14.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson53.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson31.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson47.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson16.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson17.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson11.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson13.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson49.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson1.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson22.png\n",
            "/content/Imagedataset/cropped_images/scarlett_johansson/scarlett_johansson7.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans30.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans17.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans27.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans20.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans44.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans47.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans42.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans50.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans49.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans29.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans9.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans48.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans43.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans31.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans23.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans3.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans6.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans24.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans34.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans19.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans10.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans45.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans21.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans16.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans11.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans8.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans4.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans25.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans14.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans40.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans1.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans26.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans22.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans36.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans18.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans2.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans5.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans38.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans35.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans39.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans7.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans33.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans13.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans15.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans46.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans28.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans37.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans32.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans12.png\n",
            "/content/Imagedataset/cropped_images/chris_evans/chris_evans41.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth34.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth12.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth9.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth15.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth52.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth10.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth41.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth32.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth49.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth5.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth19.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth22.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth16.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth3.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth11.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth29.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth4.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth39.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth37.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth51.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth14.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth20.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth44.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth7.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth17.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth35.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth48.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth25.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth18.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth8.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth21.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth24.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth27.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth6.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth50.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth1.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth46.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth13.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth40.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth2.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth47.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth42.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth30.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth43.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth38.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth45.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth31.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth53.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth23.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth33.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth26.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth36.png\n",
            "/content/Imagedataset/cropped_images/chris_hemsworth/chris_hemsworth28.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr33.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr30.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr10.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr11.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr15.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr12.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr37.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr44.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr6.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr26.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr19.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr34.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr24.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr29.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr18.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr13.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr32.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr46.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr23.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr2.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr22.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr49.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr31.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr41.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr21.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr42.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr25.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr8.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr50.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr28.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr48.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr47.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr14.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr9.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr4.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr5.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr40.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr20.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr45.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr35.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr3.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr38.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr36.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr27.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr51.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr39.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr1.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr43.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr17.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr7.png\n",
            "/content/Imagedataset/cropped_images/robert_downey_jr/robert_downey_jr16.png\n"
          ]
        }
      ],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/content/Imagedataset'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA SPLIT-TRAIN AND TEST SETS"
      ],
      "metadata": {
        "id": "b3y0psHKU5V3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "data_folder = '/content/Imagedataset/cropped_images/'\n",
        "train_folder = 'train'\n",
        "test_folder = 'test'\n",
        "\n",
        "split_ratio = 0.8  # Training set will contain 80% of the data\n",
        "os.makedirs(train_folder, exist_ok=True)\n",
        "os.makedirs(test_folder, exist_ok=True)\n",
        "\n",
        "for class_folder in os.listdir(data_folder):\n",
        "    class_path = os.path.join(data_folder, class_folder)\n",
        "    if not os.path.isdir(class_path):\n",
        "        continue  # Skip non-folder entries\n",
        "\n",
        "    train_class_folder = os.path.join(train_folder, class_folder)\n",
        "    test_class_folder = os.path.join(test_folder, class_folder)\n",
        "    os.makedirs(train_class_folder, exist_ok=True)\n",
        "    os.makedirs(test_class_folder, exist_ok=True)\n",
        "\n",
        "    for image_file in os.listdir(class_path):\n",
        "        image_path = os.path.join(class_path, image_file)\n",
        "\n",
        "        if random.random() < split_ratio:\n",
        "            shutil.copy2(image_path, train_class_folder)\n",
        "        else:\n",
        "            shutil.copy2(image_path, test_class_folder)\n"
      ],
      "metadata": {
        "id": "iCb9sn6LU82_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Importing Libraries"
      ],
      "metadata": {
        "id": "wr1W0sMMVcrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hide warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "g-h6f-OZVjFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from tensorflow.keras.applications.densenet import DenseNet169\n",
        "\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, ZeroPadding2D, Flatten, GlobalAveragePooling2D, InputLayer, Dropout, SpatialDropout2D, BatchNormalization, Resizing, Rescaling, RandomFlip, RandomRotation"
      ],
      "metadata": {
        "id": "gC6HtaL_VsKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine tuning"
      ],
      "metadata": {
        "id": "xYG4Gt0aWaz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dense_net = DenseNet169(weights='imagenet', include_top=False, input_shape=None)\n",
        "\n",
        "for layer in dense_net.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "iGWSBSGFWYr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting train , test , validate Images from our dirs"
      ],
      "metadata": {
        "id": "xi822hpXWlPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_folder,\n",
        "    image_size=(200, 200),\n",
        "    batch_size=64)\n",
        "\n",
        "valid_data = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_folder,\n",
        "    image_size=(200, 200),\n",
        "    batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W30-wftMWmR1",
        "outputId": "e5d6664f-ef6b-4c66-9e47-4b5d59626f33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 219 files belonging to 5 classes.\n",
            "Found 55 files belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the model"
      ],
      "metadata": {
        "id": "4uTeRPNaXgKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(dense_net)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(256 , activation ='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(128 , activation ='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PllvydabXfpn",
        "outputId": "bb08f541-5426-481d-92bd-11e1eb2a3d93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " densenet169 (Functional)    (None, None, None, 1664)  12642880  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 1664)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               426240    \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 256)              1024      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,104,197\n",
            "Trainable params: 460,549\n",
            "Non-trainable params: 12,643,648\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "train the model"
      ],
      "metadata": {
        "id": "NNQeb2m5XqHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_history = model.fit(train_data, epochs=20, validation_data=valid_data, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXiv5I7NXp3f",
        "outputId": "8685b1c2-a0b6-43d3-cd8e-3ca0468ce91c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "4/4 [==============================] - 60s 15s/step - loss: 0.4626 - accuracy: 0.8995 - val_loss: 3.2273 - val_accuracy: 0.3273\n",
            "Epoch 2/20\n",
            "4/4 [==============================] - 60s 16s/step - loss: 0.3274 - accuracy: 0.9498 - val_loss: 2.7922 - val_accuracy: 0.3091\n",
            "Epoch 3/20\n",
            "4/4 [==============================] - 53s 13s/step - loss: 0.2422 - accuracy: 0.9680 - val_loss: 2.3980 - val_accuracy: 0.3273\n",
            "Epoch 4/20\n",
            "4/4 [==============================] - 68s 19s/step - loss: 0.1788 - accuracy: 0.9817 - val_loss: 2.0212 - val_accuracy: 0.4182\n",
            "Epoch 5/20\n",
            "4/4 [==============================] - 51s 13s/step - loss: 0.1365 - accuracy: 0.9909 - val_loss: 1.8698 - val_accuracy: 0.4364\n",
            "Epoch 6/20\n",
            "4/4 [==============================] - 50s 13s/step - loss: 0.1121 - accuracy: 0.9954 - val_loss: 1.9497 - val_accuracy: 0.4364\n",
            "Epoch 7/20\n",
            "4/4 [==============================] - 60s 16s/step - loss: 0.0690 - accuracy: 1.0000 - val_loss: 1.9478 - val_accuracy: 0.4364\n",
            "Epoch 8/20\n",
            "4/4 [==============================] - 53s 13s/step - loss: 0.0581 - accuracy: 1.0000 - val_loss: 1.7849 - val_accuracy: 0.4727\n",
            "Epoch 9/20\n",
            "4/4 [==============================] - 53s 13s/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 1.6247 - val_accuracy: 0.4727\n",
            "Epoch 10/20\n",
            "4/4 [==============================] - 58s 15s/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 1.4848 - val_accuracy: 0.4909\n",
            "Epoch 11/20\n",
            "4/4 [==============================] - 67s 18s/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 1.3680 - val_accuracy: 0.5636\n",
            "Epoch 12/20\n",
            "4/4 [==============================] - 51s 13s/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 1.3550 - val_accuracy: 0.6000\n",
            "Epoch 13/20\n",
            "4/4 [==============================] - 60s 16s/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 1.3619 - val_accuracy: 0.6000\n",
            "Epoch 14/20\n",
            "4/4 [==============================] - 60s 16s/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.3556 - val_accuracy: 0.6000\n",
            "Epoch 15/20\n",
            "4/4 [==============================] - 60s 16s/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.3241 - val_accuracy: 0.6000\n",
            "Epoch 16/20\n",
            "4/4 [==============================] - 52s 13s/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 1.2735 - val_accuracy: 0.6545\n",
            "Epoch 17/20\n",
            "4/4 [==============================] - 50s 13s/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.2076 - val_accuracy: 0.6727\n",
            "Epoch 18/20\n",
            "4/4 [==============================] - 51s 13s/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.1484 - val_accuracy: 0.6727\n",
            "Epoch 19/20\n",
            "4/4 [==============================] - 60s 16s/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.1062 - val_accuracy: 0.6727\n",
            "Epoch 20/20\n",
            "4/4 [==============================] - 52s 13s/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.0958 - val_accuracy: 0.6545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the model"
      ],
      "metadata": {
        "id": "cEN3MBytX3U7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('cnn_dense.h5')"
      ],
      "metadata": {
        "id": "saUl5SFZX1EN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use The Mode With Video or Camera"
      ],
      "metadata": {
        "id": "5pgedAB-X_jZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "to access camera"
      ],
      "metadata": {
        "id": "0M5ZTDyfbGtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript\n",
        "\n",
        "def enable_camera():\n",
        "    js = Javascript('''\n",
        "        let video;\n",
        "        let stream;\n",
        "\n",
        "        async function enableCamera() {\n",
        "            stream = await navigator.mediaDevices.getUserMedia({ 'video': true });\n",
        "            video = document.createElement('video');\n",
        "            document.body.appendChild(video);\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "        }\n",
        "\n",
        "        enableCamera();\n",
        "\n",
        "        document.addEventListener('keydown', (event) => {\n",
        "            console.log('Key pressed: ' + event.key);  // Add this line for debugging\n",
        "            if (event.key === 'o') {\n",
        "                console.log('Turning off camera');  // Add this line for debugging\n",
        "                if (stream) {\n",
        "                    const tracks = stream.getTracks();\n",
        "                    tracks.forEach(track => track.stop());\n",
        "                    video.remove();\n",
        "                }\n",
        "            }\n",
        "        });\n",
        "    ''')\n",
        "    display(js)\n",
        "\n",
        "enable_camera()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "SuG758bDa_pA",
        "outputId": "604c2cf1-8423-4433-eee9-8101be116405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        let video;\n",
              "        let stream;\n",
              "        \n",
              "        async function enableCamera() {\n",
              "            stream = await navigator.mediaDevices.getUserMedia({ 'video': true });\n",
              "            video = document.createElement('video');\n",
              "            document.body.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "        }\n",
              "\n",
              "        enableCamera();\n",
              "\n",
              "        document.addEventListener('keydown', (event) => {\n",
              "            console.log('Key pressed: ' + event.key);  // Add this line for debugging\n",
              "            if (event.key === 'o') {\n",
              "                console.log('Turning off camera');  // Add this line for debugging\n",
              "                if (stream) {\n",
              "                    const tracks = stream.getTracks();\n",
              "                    tracks.forEach(track => track.stop());\n",
              "                    video.remove();\n",
              "                }\n",
              "            }\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n"
      ],
      "metadata": {
        "id": "dPtSGCz_esT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from IPython.display import display, Image\n",
        "\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "\n",
        "model = load_model('cnn_dense.h5')\n",
        "\n",
        "model_dict = {0: \"chris_evans\", 1: \"chris_hemsworth\", 2: \"mark_ruffalo\", 3: \"robert_downey_jr\", 4: \"scarlett_johansson\"}\n",
        "\n",
        "# Use the camera index that works for your system\n",
        "camera_index = 0  # You can try different values like 1 if 0 doesn't work\n",
        "\n",
        "video_capture = cv2.VideoCapture(camera_index)\n",
        "\n",
        "if not video_capture.isOpened():\n",
        "    print(\"Error: Could not open video capture.\")\n",
        "    exit()\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "def face_extractor(img):\n",
        "    faces = face_cascade.detectMultiScale(img, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "    if len(faces) == 0:\n",
        "        return None\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 255), 2)\n",
        "        cropped_face = img[y:y + h, x:x + w]\n",
        "    return cropped_face\n",
        "\n",
        "while True:\n",
        "    ret, frame = video_capture.read()\n",
        "\n",
        "    if not ret:\n",
        "        print(\"Error: Could not read a frame from the camera.\")\n",
        "        break\n",
        "\n",
        "    face = face_extractor(frame)\n",
        "    if type(face) is np.ndarray:\n",
        "        face = cv2.resize(face, (180, 180))\n",
        "        im = Image.fromarray(cv2.cvtColor(face, cv2.COLOR_BGR2RGB))\n",
        "        img_array = np.array(im)\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "        pred = model.predict(img_array)[0]\n",
        "        maxindex = int(np.argmax(pred))\n",
        "        print(maxindex)\n",
        "\n",
        "        name = \"None matching\"\n",
        "        print(pred[maxindex])\n",
        "        if pred[maxindex] > 0.4:\n",
        "            name = model_dict[maxindex]\n",
        "        cv2.putText(frame, name, (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "        _, frame_buffer = cv2.imencode('.jpg', frame)\n",
        "        if not frame_buffer.empty():\n",
        "            img_base64 = base64.b64encode(frame_buffer).decode('utf-8')\n",
        "            display(Image(data=f\"data:image/jpeg;base64,{img_base64}\"))\n",
        "    else:\n",
        "        cv2.putText(frame, \"No face found\", (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "        _, frame_buffer = cv2.imencode('.jpg', frame)\n",
        "        if not frame_buffer.empty():\n",
        "            img_base64 = base64.b64encode(frame_buffer).decode('utf-8')\n",
        "            display(Image(data=f\"data:image/jpeg;base64,{img_base64}\"))\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "video_capture.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUsDaEeMX1AR",
        "outputId": "26d4cea0-30b2-4bc7-8e7b-822bf9ee2741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Could not open video capture.\n",
            "Error: Could not read a frame from the camera.\n"
          ]
        }
      ]
    }
  ]
}